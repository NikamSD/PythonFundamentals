{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211766e1",
   "metadata": {},
   "source": [
    "# JSON Operations with Python\n",
    "\n",
    "A comprehensive guide to working with JSON files and Python objects, demonstrating all possible operations and conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc52bf8",
   "metadata": {},
   "source": [
    "## BASIC OPERATIONS\n",
    "\n",
    "### 1. Importing JSON Module and Basic Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcca303b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Module imported successfully\n",
      "JSON module version: 2.0.9\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON data types map to Python types:\n",
    "# JSON Object -> Python dict\n",
    "# JSON Array -> Python list\n",
    "# JSON String -> Python str\n",
    "# JSON Number (int) -> Python int\n",
    "# JSON Number (real) -> Python float\n",
    "# JSON true/false -> Python True/False\n",
    "# JSON null -> Python None\n",
    "\n",
    "print(\"JSON Module imported successfully\")\n",
    "print(f\"JSON module version: {json.__version__ if hasattr(json, '__version__') else 'Built-in'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06f22a",
   "metadata": {},
   "source": [
    "### 2. Python Object to JSON String (Serialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e02fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary to JSON: {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\n",
      "Type: <class 'str'>\n",
      "\n",
      "List to JSON: [\"apple\", \"banana\", \"cherry\"]\n",
      "\n",
      "Nested to JSON: {\"users\": [{\"id\": 1, \"name\": \"Alice\", \"active\": true}, {\"id\": 2, \"name\": \"Bob\", \"active\": false}], \"count\": 2, \"meta\": null}\n",
      "\n",
      "Pretty JSON:\n",
      " {\n",
      "    \"users\": [\n",
      "        {\n",
      "            \"id\": 1,\n",
      "            \"name\": \"Alice\",\n",
      "            \"active\": true\n",
      "        },\n",
      "        {\n",
      "            \"id\": 2,\n",
      "            \"name\": \"Bob\",\n",
      "            \"active\": false\n",
      "        }\n",
      "    ],\n",
      "    \"count\": 2,\n",
      "    \"meta\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# json.dumps() - Convert Python object to JSON string\n",
    "\n",
    "# Dictionary to JSON\n",
    "person = {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\n",
    "json_string = json.dumps(person)\n",
    "print(\"Dictionary to JSON:\", json_string)\n",
    "print(\"Type:\", type(json_string))\n",
    "\n",
    "# List to JSON\n",
    "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
    "json_list = json.dumps(fruits)\n",
    "print(\"\\nList to JSON:\", json_list)\n",
    "\n",
    "# Nested structure to JSON\n",
    "data = {\n",
    "    \"users\": [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"active\": True},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"active\": False}\n",
    "    ],\n",
    "    \"count\": 2,\n",
    "    \"meta\": None\n",
    "}\n",
    "json_nested = json.dumps(data)\n",
    "print(\"\\nNested to JSON:\", json_nested)\n",
    "\n",
    "# Pretty printing with indent\n",
    "json_pretty = json.dumps(data, indent=4)\n",
    "print(\"\\nPretty JSON:\\n\", json_pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee748a",
   "metadata": {},
   "source": [
    "### 3. JSON String to Python Object (Deserialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e20f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON to Dictionary: {'name': 'Alice', 'age': 30, 'city': 'New York'}\n",
      "Type: <class 'dict'>\n",
      "Access name: Alice\n",
      "\n",
      "JSON to List: ['apple', 'banana', 'cherry']\n",
      "\n",
      "Complex JSON to Python:\n",
      "First user: Alice\n",
      "First user scores: [95, 87, 92]\n"
     ]
    }
   ],
   "source": [
    "# json.loads() - Convert JSON string to Python object\n",
    "import json\n",
    "# JSON string to dictionary\n",
    "json_str = '{\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}'\n",
    "python_dict = json.loads(json_str)\n",
    "print(\"JSON to Dictionary:\", python_dict)\n",
    "print(\"Type:\", type(python_dict))\n",
    "print(\"Access name:\", python_dict[\"name\"])\n",
    "\n",
    "# JSON array to list\n",
    "json_array = '[\"apple\", \"banana\", \"cherry\"]'\n",
    "python_list = json.loads(json_array)\n",
    "print(\"\\nJSON to List:\", python_list)\n",
    "\n",
    "# Complex JSON to nested Python objects\n",
    "json_complex = '''\n",
    "{\n",
    "    \"users\": [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"scores\": [95, 87, 92]},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"scores\": [88, 91, 85]}\n",
    "    ],\n",
    "    \"total\": 2\n",
    "}\n",
    "'''\n",
    "python_obj = json.loads(json_complex)\n",
    "print(\"\\nComplex JSON to Python:\")\n",
    "print(f\"First user: {python_obj['users'][0]['name']}\")\n",
    "print(f\"First user scores: {python_obj['users'][0]['scores']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd832457",
   "metadata": {},
   "source": [
    "### 4. Writing Python Objects to JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump() - Write Python object to JSON file\n",
    "\n",
    "# Writing a simple dictionary\n",
    "person = {\n",
    "    \"name\": \"Alice Johnson\",\n",
    "    \"age\": 30,\n",
    "    \"email\": \"alice@example.com\",\n",
    "    \"is_active\": True\n",
    "}\n",
    "\n",
    "with open(\"person.json\", \"w\") as file:\n",
    "    json.dump(person, file, indent=4)\n",
    "print(\"Created person.json\")\n",
    "\n",
    "# Writing a list of dictionaries\n",
    "students = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"grade\": \"A\", \"subjects\": [\"Math\", \"Science\"]},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"grade\": \"B\", \"subjects\": [\"English\", \"History\"]},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"grade\": \"A\", \"subjects\": [\"Math\", \"Physics\"]}\n",
    "]\n",
    "\n",
    "with open(\"students.json\", \"w\") as file:\n",
    "    json.dump(students, file, indent=2)\n",
    "print(\"Created students.json\")\n",
    "\n",
    "# Writing nested complex structure\n",
    "company = {\n",
    "    \"name\": \"TechCorp\",\n",
    "    \"employees\": [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"department\": \"Engineering\", \"salary\": 75000},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"department\": \"Sales\", \"salary\": 65000}\n",
    "    ],\n",
    "    \"departments\": {\n",
    "        \"Engineering\": {\"budget\": 500000, \"head\": \"Alice\"},\n",
    "        \"Sales\": {\"budget\": 300000, \"head\": \"Bob\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"company.json\", \"w\") as file:\n",
    "    json.dump(company, file, indent=4, sort_keys=True)\n",
    "print(\"Created company.json with sorted keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6278a0f3",
   "metadata": {},
   "source": [
    "### 5. Reading JSON Files to Python Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a532a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.load() - Read JSON file to Python object\n",
    "\n",
    "# Reading person.json\n",
    "with open(\"person.json\", \"r\") as file:\n",
    "    person_data = json.load(file)\n",
    "print(\"Person data:\", person_data)\n",
    "print(\"Name:\", person_data[\"name\"])\n",
    "\n",
    "# Reading students.json\n",
    "with open(\"students.json\", \"r\") as file:\n",
    "    students_data = json.load(file)\n",
    "print(\"\\nNumber of students:\", len(students_data))\n",
    "for student in students_data:\n",
    "    print(f\"  {student['name']}: Grade {student['grade']}\")\n",
    "\n",
    "# Reading company.json\n",
    "with open(\"company.json\", \"r\") as file:\n",
    "    company_data = json.load(file)\n",
    "print(\"\\nCompany name:\", company_data[\"name\"])\n",
    "print(\"Departments:\", list(company_data[\"departments\"].keys()))\n",
    "print(\"First employee:\", company_data[\"employees\"][0][\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fe119",
   "metadata": {},
   "source": [
    "## INTERMEDIATE OPERATIONS\n",
    "\n",
    "### 6. JSON Formatting Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\": \"Alice\", \"age\": 30, \"skills\": [\"Python\", \"JavaScript\", \"SQL\"]}\n",
    "\n",
    "# Default compact format\n",
    "compact = json.dumps(data)\n",
    "print(\"Compact:\", compact)\n",
    "\n",
    "# With indentation\n",
    "indented = json.dumps(data, indent=4)\n",
    "print(\"\\nIndented (4 spaces):\\n\", indented)\n",
    "\n",
    "# With sorted keys\n",
    "sorted_json = json.dumps(data, indent=2, sort_keys=True)\n",
    "print(\"\\nSorted keys:\\n\", sorted_json)\n",
    "\n",
    "# Custom separators (remove spaces)\n",
    "compact_custom = json.dumps(data, separators=(',', ':'))\n",
    "print(\"\\nCompact with custom separators:\", compact_custom)\n",
    "\n",
    "# Readable separators\n",
    "readable = json.dumps(data, indent=4, separators=(', ', ': '))\n",
    "print(\"\\nReadable separators:\\n\", readable)\n",
    "\n",
    "# Ensure ASCII (for non-ASCII characters)\n",
    "unicode_data = {\"name\": \"JosÃ©\", \"city\": \"SÃ£o Paulo\"}\n",
    "ascii_json = json.dumps(unicode_data, ensure_ascii=True)\n",
    "print(\"\\nASCII encoded:\", ascii_json)\n",
    "non_ascii = json.dumps(unicode_data, ensure_ascii=False)\n",
    "print(\"Non-ASCII:\", non_ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d484224",
   "metadata": {},
   "source": [
    "### 7. Working with Different Python Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with various types\n",
    "data_dict = {\n",
    "    \"string\": \"hello\",\n",
    "    \"integer\": 42,\n",
    "    \"float\": 3.14,\n",
    "    \"boolean\": True,\n",
    "    \"null\": None,\n",
    "    \"list\": [1, 2, 3],\n",
    "    \"nested_dict\": {\"key\": \"value\"}\n",
    "}\n",
    "print(\"Dictionary to JSON:\")\n",
    "print(json.dumps(data_dict, indent=2))\n",
    "\n",
    "# List with mixed types\n",
    "data_list = [1, \"two\", 3.0, True, None, {\"key\": \"value\"}, [1, 2]]\n",
    "print(\"\\nList to JSON:\")\n",
    "print(json.dumps(data_list, indent=2))\n",
    "\n",
    "# Tuple (converts to JSON array)\n",
    "data_tuple = (1, 2, 3, \"four\")\n",
    "print(\"\\nTuple to JSON:\", json.dumps(data_tuple))\n",
    "\n",
    "# Set - NOT directly serializable (will cause error)\n",
    "# Workaround: convert to list\n",
    "data_set = {1, 2, 3, 4}\n",
    "print(\"\\nSet to JSON (as list):\", json.dumps(list(data_set)))\n",
    "\n",
    "# Dictionary with tuple keys - NOT directly serializable\n",
    "# Workaround: convert keys to strings\n",
    "dict_with_tuple_keys = {(1, 2): \"value\"}\n",
    "converted = {str(k): v for k, v in dict_with_tuple_keys.items()}\n",
    "print(\"\\nDict with tuple keys (converted):\", json.dumps(converted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66999e0d",
   "metadata": {},
   "source": [
    "### 8. Handling Custom Objects with JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72621070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom class\n",
    "class Person:\n",
    "    def __init__(self, name, age, email):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.email = email\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Convert object to dictionary\"\"\"\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"age\": self.age,\n",
    "            \"email\": self.email\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dict(cls, data):\n",
    "        \"\"\"Create object from dictionary\"\"\"\n",
    "        return cls(data[\"name\"], data[\"age\"], data[\"email\"])\n",
    "\n",
    "# Create person object\n",
    "person = Person(\"Alice\", 30, \"alice@example.com\")\n",
    "\n",
    "# Method 1: Using to_dict() method\n",
    "person_json = json.dumps(person.to_dict(), indent=2)\n",
    "print(\"Person to JSON (using to_dict):\")\n",
    "print(person_json)\n",
    "\n",
    "# Method 2: Custom encoder\n",
    "class PersonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, Person):\n",
    "            return obj.to_dict()\n",
    "        return super().default(obj)\n",
    "\n",
    "person_json2 = json.dumps(person, cls=PersonEncoder, indent=2)\n",
    "print(\"\\nPerson to JSON (using custom encoder):\")\n",
    "print(person_json2)\n",
    "\n",
    "# Deserialize back to object\n",
    "person_data = json.loads(person_json)\n",
    "restored_person = Person.from_dict(person_data)\n",
    "print(f\"\\nRestored person: {restored_person.name}, age {restored_person.age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a31420",
   "metadata": {},
   "source": [
    "### 9. Error Handling with JSON Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d79732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling invalid JSON strings\n",
    "invalid_json = '{\"name\": \"Alice\", \"age\": 30,}'  # Trailing comma\n",
    "\n",
    "try:\n",
    "    data = json.loads(invalid_json)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSONDecodeError: {e}\")\n",
    "    print(f\"Error at line {e.lineno}, column {e.colno}\")\n",
    "\n",
    "# Handling file not found\n",
    "try:\n",
    "    with open(\"nonexistent.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nFile not found error handled\")\n",
    "\n",
    "# Handling non-serializable objects\n",
    "class CustomObject:\n",
    "    pass\n",
    "\n",
    "obj = CustomObject()\n",
    "\n",
    "try:\n",
    "    json.dumps(obj)\n",
    "except TypeError as e:\n",
    "    print(f\"\\nTypeError: {e}\")\n",
    "    print(\"Solution: Provide custom encoder or convert to dict\")\n",
    "\n",
    "# Safe JSON loading with error handling\n",
    "def safe_load_json(filename):\n",
    "    try:\n",
    "        with open(filename, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Invalid JSON in {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test safe loading\n",
    "result = safe_load_json(\"person.json\")\n",
    "if result:\n",
    "    print(f\"\\nSuccessfully loaded: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603356b",
   "metadata": {},
   "source": [
    "### 10. Updating and Modifying JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab632923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read, modify, and write back\n",
    "with open(\"person.json\", \"r\") as file:\n",
    "    person = json.load(file)\n",
    "\n",
    "print(\"Original:\", person)\n",
    "\n",
    "# Update existing field\n",
    "person[\"age\"] = 31\n",
    "\n",
    "# Add new field\n",
    "person[\"phone\"] = \"555-1234\"\n",
    "\n",
    "# Write back to file\n",
    "with open(\"person.json\", \"w\") as file:\n",
    "    json.dump(person, file, indent=4)\n",
    "\n",
    "print(\"Updated:\", person)\n",
    "\n",
    "# Update nested data in students.json\n",
    "with open(\"students.json\", \"r\") as file:\n",
    "    students = json.load(file)\n",
    "\n",
    "# Add a new student\n",
    "new_student = {\n",
    "    \"id\": 4,\n",
    "    \"name\": \"Diana\",\n",
    "    \"grade\": \"A\",\n",
    "    \"subjects\": [\"Chemistry\", \"Biology\"]\n",
    "}\n",
    "students.append(new_student)\n",
    "\n",
    "# Update existing student grade\n",
    "for student in students:\n",
    "    if student[\"name\"] == \"Bob\":\n",
    "        student[\"grade\"] = \"A\"\n",
    "        break\n",
    "\n",
    "# Write back\n",
    "with open(\"students.json\", \"w\") as file:\n",
    "    json.dump(students, file, indent=2)\n",
    "\n",
    "print(f\"\\nUpdated students count: {len(students)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70068886",
   "metadata": {},
   "source": [
    "## ADVANCED OPERATIONS\n",
    "\n",
    "### 11. Working with Large JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a large JSON file for demonstration\n",
    "large_data = {\n",
    "    \"records\": [\n",
    "        {\"id\": i, \"name\": f\"User{i}\", \"score\": i * 10}\n",
    "        for i in range(1000)\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"large_data.json\", \"w\") as file:\n",
    "    json.dump(large_data, file)\n",
    "\n",
    "print(\"Created large_data.json with 1000 records\")\n",
    "\n",
    "# Streaming large JSON file - processing line by line\n",
    "# For JSON Lines format (one JSON object per line)\n",
    "with open(\"data_stream.jsonl\", \"w\") as file:\n",
    "    for i in range(100):\n",
    "        record = {\"id\": i, \"value\": i ** 2}\n",
    "        file.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "print(\"Created data_stream.jsonl\")\n",
    "\n",
    "# Reading JSON Lines format\n",
    "records = []\n",
    "with open(\"data_stream.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        record = json.loads(line.strip())\n",
    "        records.append(record)\n",
    "\n",
    "print(f\"Read {len(records)} records from JSON Lines file\")\n",
    "print(f\"First record: {records[0]}\")\n",
    "print(f\"Last record: {records[-1]}\")\n",
    "\n",
    "# Partial loading - read specific parts\n",
    "with open(\"large_data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    # Process only first 10 records\n",
    "    first_10 = data[\"records\"][:10]\n",
    "    print(f\"\\nFirst 10 records from large file: {len(first_10)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5df71",
   "metadata": {},
   "source": [
    "### 12. JSON Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf7d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual validation - checking structure and types\n",
    "def validate_person(data):\n",
    "    \"\"\"Validate person data structure\"\"\"\n",
    "    required_fields = [\"name\", \"age\", \"email\"]\n",
    "    \n",
    "    # Check all required fields present\n",
    "    for field in required_fields:\n",
    "        if field not in data:\n",
    "            return False, f\"Missing required field: {field}\"\n",
    "    \n",
    "    # Check types\n",
    "    if not isinstance(data[\"name\"], str):\n",
    "        return False, \"Name must be string\"\n",
    "    if not isinstance(data[\"age\"], int):\n",
    "        return False, \"Age must be integer\"\n",
    "    if not isinstance(data[\"email\"], str):\n",
    "        return False, \"Email must be string\"\n",
    "    \n",
    "    # Check value constraints\n",
    "    if data[\"age\"] < 0 or data[\"age\"] > 150:\n",
    "        return False, \"Age must be between 0 and 150\"\n",
    "    \n",
    "    return True, \"Valid\"\n",
    "\n",
    "# Test validation\n",
    "valid_person = {\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"}\n",
    "invalid_person = {\"name\": \"Bob\", \"age\": \"thirty\"}  # age is string, not int\n",
    "\n",
    "is_valid, message = validate_person(valid_person)\n",
    "print(f\"Valid person: {is_valid} - {message}\")\n",
    "\n",
    "is_valid, message = validate_person(invalid_person)\n",
    "print(f\"Invalid person: {is_valid} - {message}\")\n",
    "\n",
    "# Validate nested structure\n",
    "def validate_student(data):\n",
    "    \"\"\"Validate student data\"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        return False, \"Student must be a dictionary\"\n",
    "    \n",
    "    required = [\"id\", \"name\", \"grade\", \"subjects\"]\n",
    "    if not all(field in data for field in required):\n",
    "        return False, \"Missing required fields\"\n",
    "    \n",
    "    if not isinstance(data[\"subjects\"], list):\n",
    "        return False, \"Subjects must be a list\"\n",
    "    \n",
    "    if data[\"grade\"] not in [\"A\", \"B\", \"C\", \"D\", \"F\"]:\n",
    "        return False, \"Invalid grade\"\n",
    "    \n",
    "    return True, \"Valid\"\n",
    "\n",
    "valid_student = {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"Alice\",\n",
    "    \"grade\": \"A\",\n",
    "    \"subjects\": [\"Math\", \"Science\"]\n",
    "}\n",
    "\n",
    "is_valid, message = validate_student(valid_student)\n",
    "print(f\"\\nValid student: {is_valid} - {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad790e62",
   "metadata": {},
   "source": [
    "### 13. Merging and Combining JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b566722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two dictionaries\n",
    "config1 = {\"host\": \"localhost\", \"port\": 8080, \"debug\": True}\n",
    "config2 = {\"port\": 9000, \"timeout\": 30}\n",
    "\n",
    "# Method 1: update()\n",
    "merged1 = config1.copy()\n",
    "merged1.update(config2)\n",
    "print(\"Merged with update():\", json.dumps(merged1, indent=2))\n",
    "\n",
    "# Method 2: unpacking operator\n",
    "merged2 = {**config1, **config2}\n",
    "print(\"\\nMerged with unpacking:\", json.dumps(merged2, indent=2))\n",
    "\n",
    "# Merging lists from multiple JSON files\n",
    "data1 = {\"users\": [{\"id\": 1, \"name\": \"Alice\"}]}\n",
    "data2 = {\"users\": [{\"id\": 2, \"name\": \"Bob\"}]}\n",
    "\n",
    "combined_users = data1[\"users\"] + data2[\"users\"]\n",
    "print(\"\\nCombined users:\", json.dumps(combined_users, indent=2))\n",
    "\n",
    "# Deep merge of nested dictionaries\n",
    "def deep_merge(dict1, dict2):\n",
    "    \"\"\"Recursively merge dict2 into dict1\"\"\"\n",
    "    result = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n",
    "            result[key] = deep_merge(result[key], value)\n",
    "        else:\n",
    "            result[key] = value\n",
    "    return result\n",
    "\n",
    "nested1 = {\n",
    "    \"database\": {\"host\": \"localhost\", \"port\": 5432},\n",
    "    \"cache\": {\"enabled\": True}\n",
    "}\n",
    "nested2 = {\n",
    "    \"database\": {\"user\": \"admin\", \"password\": \"secret\"},\n",
    "    \"logging\": {\"level\": \"INFO\"}\n",
    "}\n",
    "\n",
    "deep_merged = deep_merge(nested1, nested2)\n",
    "print(\"\\nDeep merged:\", json.dumps(deep_merged, indent=2))\n",
    "\n",
    "# Combining multiple JSON files\n",
    "json_files = [\"person.json\", \"students.json\"]\n",
    "combined_data = {}\n",
    "\n",
    "for filename in json_files:\n",
    "    try:\n",
    "        with open(filename, \"r\") as file:\n",
    "            combined_data[filename.replace(\".json\", \"\")] = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {filename} not found\")\n",
    "\n",
    "print(f\"\\nCombined data keys: {list(combined_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ab0a6",
   "metadata": {},
   "source": [
    "### 14. Filtering and Transforming JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "products = [\n",
    "    {\"id\": 1, \"name\": \"Laptop\", \"price\": 1200, \"category\": \"Electronics\", \"in_stock\": True},\n",
    "    {\"id\": 2, \"name\": \"Mouse\", \"price\": 25, \"category\": \"Electronics\", \"in_stock\": True},\n",
    "    {\"id\": 3, \"name\": \"Desk\", \"price\": 350, \"category\": \"Furniture\", \"in_stock\": False},\n",
    "    {\"id\": 4, \"name\": \"Chair\", \"price\": 180, \"category\": \"Furniture\", \"in_stock\": True}\n",
    "]\n",
    "\n",
    "# Filter by condition\n",
    "expensive_products = [p for p in products if p[\"price\"] > 100]\n",
    "print(\"Expensive products:\", json.dumps(expensive_products, indent=2))\n",
    "\n",
    "# Filter by multiple conditions\n",
    "available_electronics = [\n",
    "    p for p in products \n",
    "    if p[\"category\"] == \"Electronics\" and p[\"in_stock\"]\n",
    "]\n",
    "print(\"\\nAvailable electronics:\", json.dumps(available_electronics, indent=2))\n",
    "\n",
    "# Transform - extract specific fields\n",
    "product_names = [{\"id\": p[\"id\"], \"name\": p[\"name\"]} for p in products]\n",
    "print(\"\\nProduct names only:\", json.dumps(product_names, indent=2))\n",
    "\n",
    "# Transform - add calculated fields\n",
    "with_tax = [\n",
    "    {**p, \"price_with_tax\": round(p[\"price\"] * 1.1, 2)}\n",
    "    for p in products\n",
    "]\n",
    "print(\"\\nWith tax:\", json.dumps(with_tax, indent=2))\n",
    "\n",
    "# Group by category\n",
    "from collections import defaultdict\n",
    "by_category = defaultdict(list)\n",
    "for product in products:\n",
    "    by_category[product[\"category\"]].append(product)\n",
    "\n",
    "print(\"\\nGrouped by category:\", json.dumps(dict(by_category), indent=2))\n",
    "\n",
    "# Aggregate operations\n",
    "total_value = sum(p[\"price\"] for p in products if p[\"in_stock\"])\n",
    "print(f\"\\nTotal value of in-stock items: ${total_value}\")\n",
    "\n",
    "# Sort by field\n",
    "sorted_by_price = sorted(products, key=lambda x: x[\"price\"], reverse=True)\n",
    "print(\"\\nSorted by price (desc):\", json.dumps(sorted_by_price, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3d8fb3",
   "metadata": {},
   "source": [
    "### 15. Working with Nested JSON Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex nested structure\n",
    "organization = {\n",
    "    \"name\": \"TechCorp\",\n",
    "    \"departments\": [\n",
    "        {\n",
    "            \"name\": \"Engineering\",\n",
    "            \"employees\": [\n",
    "                {\n",
    "                    \"id\": 1,\n",
    "                    \"name\": \"Alice\",\n",
    "                    \"skills\": [\"Python\", \"JavaScript\"],\n",
    "                    \"projects\": [\n",
    "                        {\"id\": 101, \"name\": \"Project A\", \"status\": \"active\"},\n",
    "                        {\"id\": 102, \"name\": \"Project B\", \"status\": \"completed\"}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"id\": 2,\n",
    "                    \"name\": \"Bob\",\n",
    "                    \"skills\": [\"Java\", \"C++\"],\n",
    "                    \"projects\": [\n",
    "                        {\"id\": 103, \"name\": \"Project C\", \"status\": \"active\"}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Sales\",\n",
    "            \"employees\": [\n",
    "                {\n",
    "                    \"id\": 3,\n",
    "                    \"name\": \"Charlie\",\n",
    "                    \"skills\": [\"Communication\", \"Negotiation\"],\n",
    "                    \"projects\": []\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save nested structure\n",
    "with open(\"organization.json\", \"w\") as file:\n",
    "    json.dump(organization, file, indent=2)\n",
    "print(\"Created organization.json\")\n",
    "\n",
    "# Navigate nested structure\n",
    "print(f\"\\nOrganization: {organization['name']}\")\n",
    "print(f\"Departments: {len(organization['departments'])}\")\n",
    "\n",
    "# Access deeply nested data\n",
    "first_dept = organization[\"departments\"][0]\n",
    "first_employee = first_dept[\"employees\"][0]\n",
    "print(f\"First employee: {first_employee['name']}\")\n",
    "print(f\"Skills: {', '.join(first_employee['skills'])}\")\n",
    "\n",
    "# Iterate through nested structure\n",
    "for dept in organization[\"departments\"]:\n",
    "    print(f\"\\nDepartment: {dept['name']}\")\n",
    "    for emp in dept[\"employees\"]:\n",
    "        print(f\"  Employee: {emp['name']}\")\n",
    "        active_projects = [p for p in emp[\"projects\"] if p[\"status\"] == \"active\"]\n",
    "        print(f\"    Active projects: {len(active_projects)}\")\n",
    "\n",
    "# Flatten nested structure\n",
    "all_employees = []\n",
    "for dept in organization[\"departments\"]:\n",
    "    for emp in dept[\"employees\"]:\n",
    "        emp_copy = emp.copy()\n",
    "        emp_copy[\"department\"] = dept[\"name\"]\n",
    "        all_employees.append(emp_copy)\n",
    "\n",
    "print(f\"\\nFlattened: {len(all_employees)} total employees\")\n",
    "print(json.dumps(all_employees, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9209e10",
   "metadata": {},
   "source": [
    "### 16. JSON with Different Python Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with lists\n",
    "list_data = {\n",
    "    \"numbers\": [1, 2, 3, 4, 5],\n",
    "    \"names\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"mixed\": [1, \"two\", 3.0, True, None]\n",
    "}\n",
    "print(\"List data:\", json.dumps(list_data, indent=2))\n",
    "\n",
    "# Working with tuples (converted to arrays)\n",
    "tuple_data = {\n",
    "    \"coordinates\": (10, 20),\n",
    "    \"rgb\": (255, 128, 0)\n",
    "}\n",
    "# Tuples become lists in JSON\n",
    "print(\"\\nTuple data:\", json.dumps(tuple_data, indent=2))\n",
    "\n",
    "# After loading, they're lists\n",
    "json_str = json.dumps(tuple_data)\n",
    "loaded = json.loads(json_str)\n",
    "print(f\"Type of coordinates: {type(loaded['coordinates'])}\")  # list, not tuple\n",
    "\n",
    "# Working with sets (must convert to list)\n",
    "unique_tags = {\"python\", \"json\", \"programming\", \"tutorial\"}\n",
    "set_data = {\n",
    "    \"tags\": list(unique_tags),  # Convert set to list\n",
    "    \"count\": len(unique_tags)\n",
    "}\n",
    "print(\"\\nSet data (as list):\", json.dumps(set_data, indent=2))\n",
    "\n",
    "# Nested collections\n",
    "nested_collections = {\n",
    "    \"matrix\": [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "    \"users\": [\n",
    "        {\"name\": \"Alice\", \"scores\": [95, 87, 92]},\n",
    "        {\"name\": \"Bob\", \"scores\": [88, 91, 85]}\n",
    "    ],\n",
    "    \"departments\": {\n",
    "        \"eng\": [\"Alice\", \"Bob\"],\n",
    "        \"sales\": [\"Charlie\", \"Diana\"]\n",
    "    }\n",
    "}\n",
    "print(\"\\nNested collections:\", json.dumps(nested_collections, indent=2))\n",
    "\n",
    "# Converting back with specific types\n",
    "json_data = '{\"point\": [10, 20], \"tags\": [\"python\", \"json\"]}'\n",
    "loaded_data = json.loads(json_data)\n",
    "\n",
    "# Convert list back to tuple if needed\n",
    "point_tuple = tuple(loaded_data[\"point\"])\n",
    "print(f\"\\nConverted point to tuple: {point_tuple}, type: {type(point_tuple)}\")\n",
    "\n",
    "# Convert list back to set if needed\n",
    "tags_set = set(loaded_data[\"tags\"])\n",
    "print(f\"Converted tags to set: {tags_set}, type: {type(tags_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ab7c9",
   "metadata": {},
   "source": [
    "### 17. Practical Use Cases and Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ade98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 1: Configuration file management\n",
    "config = {\n",
    "    \"app_name\": \"MyApp\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"database\": {\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 5432,\n",
    "        \"name\": \"mydb\"\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"authentication\": True,\n",
    "        \"logging\": True,\n",
    "        \"debug_mode\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config\n",
    "with open(\"config.json\", \"w\") as file:\n",
    "    json.dump(config, file, indent=4)\n",
    "\n",
    "# Load and use config\n",
    "with open(\"config.json\", \"r\") as file:\n",
    "    app_config = json.load(file)\n",
    "    print(f\"Starting {app_config['app_name']} v{app_config['version']}\")\n",
    "    print(f\"Database: {app_config['database']['host']}:{app_config['database']['port']}\")\n",
    "\n",
    "# Use Case 2: API response simulation\n",
    "api_response = {\n",
    "    \"status\": \"success\",\n",
    "    \"data\": {\n",
    "        \"users\": [\n",
    "            {\"id\": 1, \"username\": \"alice\", \"active\": True},\n",
    "            {\"id\": 2, \"username\": \"bob\", \"active\": False}\n",
    "        ],\n",
    "        \"total\": 2,\n",
    "        \"page\": 1\n",
    "    },\n",
    "    \"timestamp\": \"2025-11-20T10:30:00Z\"\n",
    "}\n",
    "\n",
    "print(\"\\nAPI Response:\", json.dumps(api_response, indent=2))\n",
    "\n",
    "# Use Case 3: Data export/import\n",
    "users_db = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\", \"created\": \"2025-01-01\"},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\", \"created\": \"2025-01-02\"}\n",
    "]\n",
    "\n",
    "# Export to JSON\n",
    "with open(\"users_export.json\", \"w\") as file:\n",
    "    json.dump(users_db, file, indent=2)\n",
    "print(\"\\nUsers exported to users_export.json\")\n",
    "\n",
    "# Import from JSON\n",
    "with open(\"users_export.json\", \"r\") as file:\n",
    "    imported_users = json.load(file)\n",
    "print(f\"Imported {len(imported_users)} users\")\n",
    "\n",
    "# Use Case 4: Caching data\n",
    "cache = {}\n",
    "\n",
    "def get_data_with_cache(key):\n",
    "    \"\"\"Simulate data retrieval with JSON cache\"\"\"\n",
    "    cache_file = \"cache.json\"\n",
    "    \n",
    "    # Try to load cache\n",
    "    try:\n",
    "        with open(cache_file, \"r\") as file:\n",
    "            cache = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        cache = {}\n",
    "    \n",
    "    # Check if data in cache\n",
    "    if key in cache:\n",
    "        print(f\"Cache hit for '{key}'\")\n",
    "        return cache[key]\n",
    "    \n",
    "    # Simulate data retrieval\n",
    "    print(f\"Cache miss for '{key}', fetching...\")\n",
    "    data = f\"Data for {key}\"\n",
    "    \n",
    "    # Update cache\n",
    "    cache[key] = data\n",
    "    with open(cache_file, \"w\") as file:\n",
    "        json.dump(cache, file, indent=2)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Test caching\n",
    "result1 = get_data_with_cache(\"user_1\")\n",
    "result2 = get_data_with_cache(\"user_1\")  # Should hit cache\n",
    "\n",
    "# Use Case 5: Settings with defaults\n",
    "default_settings = {\n",
    "    \"theme\": \"light\",\n",
    "    \"language\": \"en\",\n",
    "    \"notifications\": True\n",
    "}\n",
    "\n",
    "# Load user settings with defaults\n",
    "def load_settings():\n",
    "    try:\n",
    "        with open(\"user_settings.json\", \"r\") as file:\n",
    "            user_settings = json.load(file)\n",
    "        # Merge with defaults\n",
    "        return {**default_settings, **user_settings}\n",
    "    except FileNotFoundError:\n",
    "        return default_settings.copy()\n",
    "\n",
    "settings = load_settings()\n",
    "print(f\"\\nActive settings: {json.dumps(settings, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b791d",
   "metadata": {},
   "source": [
    "### 18. Advanced Techniques: Custom Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aefdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from decimal import Decimal\n",
    "\n",
    "# Handling datetime objects\n",
    "class DateTimeEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (datetime, date)):\n",
    "            return obj.isoformat()\n",
    "        if isinstance(obj, Decimal):\n",
    "            return float(obj)\n",
    "        return super().default(obj)\n",
    "\n",
    "# Data with datetime\n",
    "event = {\n",
    "    \"name\": \"Conference\",\n",
    "    \"start_date\": datetime(2025, 11, 20, 10, 30),\n",
    "    \"end_date\": date(2025, 11, 21),\n",
    "    \"price\": Decimal(\"299.99\")\n",
    "}\n",
    "\n",
    "# Serialize with custom encoder\n",
    "event_json = json.dumps(event, cls=DateTimeEncoder, indent=2)\n",
    "print(\"Event with datetime:\", event_json)\n",
    "\n",
    "# Alternative: Using default parameter\n",
    "def json_serial(obj):\n",
    "    \"\"\"JSON serializer for objects not serializable by default\"\"\"\n",
    "    if isinstance(obj, (datetime, date)):\n",
    "        return obj.isoformat()\n",
    "    if isinstance(obj, Decimal):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "event_json2 = json.dumps(event, default=json_serial, indent=2)\n",
    "print(\"\\nUsing default parameter:\", event_json2)\n",
    "\n",
    "# Handling complex custom objects\n",
    "class Employee:\n",
    "    def __init__(self, name, employee_id, hire_date):\n",
    "        self.name = name\n",
    "        self.employee_id = employee_id\n",
    "        self.hire_date = hire_date\n",
    "    \n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"employee_id\": self.employee_id,\n",
    "            \"hire_date\": self.hire_date.isoformat()\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, data):\n",
    "        data[\"hire_date\"] = datetime.fromisoformat(data[\"hire_date\"]).date()\n",
    "        return cls(**data)\n",
    "\n",
    "# Create and serialize employee\n",
    "emp = Employee(\"Alice Johnson\", \"EMP001\", date(2023, 1, 15))\n",
    "\n",
    "def employee_encoder(obj):\n",
    "    if isinstance(obj, Employee):\n",
    "        return obj.to_json()\n",
    "    if isinstance(obj, (datetime, date)):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "emp_json = json.dumps(emp, default=employee_encoder, indent=2)\n",
    "print(\"\\nEmployee JSON:\", emp_json)\n",
    "\n",
    "# Deserialize back\n",
    "emp_data = json.loads(emp_json)\n",
    "emp_restored = Employee.from_json(emp_data)\n",
    "print(f\"Restored employee: {emp_restored.name}, ID: {emp_restored.employee_id}\")\n",
    "\n",
    "# Handling nested complex objects\n",
    "company_data = {\n",
    "    \"name\": \"TechCorp\",\n",
    "    \"founded\": date(2020, 1, 1),\n",
    "    \"employees\": [\n",
    "        Employee(\"Alice\", \"E001\", date(2023, 1, 15)),\n",
    "        Employee(\"Bob\", \"E002\", date(2023, 2, 1))\n",
    "    ]\n",
    "}\n",
    "\n",
    "company_json = json.dumps(company_data, default=employee_encoder, indent=2)\n",
    "print(\"\\nCompany with employees:\", company_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8845eb1d",
   "metadata": {},
   "source": [
    "### 19. Performance Tips and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf780120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Performance comparison: dumps vs dump\n",
    "data = {\"records\": [{\"id\": i, \"value\": i * 10} for i in range(1000)]}\n",
    "\n",
    "# Method 1: dumps then write\n",
    "start = time.time()\n",
    "json_str = json.dumps(data)\n",
    "with open(\"perf_test1.json\", \"w\") as file:\n",
    "    file.write(json_str)\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Method 2: dump directly\n",
    "start = time.time()\n",
    "with open(\"perf_test2.json\", \"w\") as file:\n",
    "    json.dump(data, file)\n",
    "time2 = time.time() - start\n",
    "\n",
    "print(f\"dumps + write: {time1:.4f}s\")\n",
    "print(f\"dump directly: {time2:.4f}s\")\n",
    "print(f\"dump is {time1/time2:.2f}x faster\\n\")\n",
    "\n",
    "# Best Practice 1: Use context managers (with statement)\n",
    "# Good\n",
    "with open(\"data.json\", \"w\") as file:\n",
    "    json.dump(data, file)\n",
    "print(\"âœ“ Always use 'with' statement for file operations\")\n",
    "\n",
    "# Best Practice 2: Validate before saving\n",
    "def save_json_safely(data, filename):\n",
    "    \"\"\"Safely save JSON with validation\"\"\"\n",
    "    # Validate data can be serialized\n",
    "    try:\n",
    "        json.dumps(data)\n",
    "    except (TypeError, ValueError) as e:\n",
    "        print(f\"Data validation failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Save to file\n",
    "    try:\n",
    "        with open(filename, \"w\") as file:\n",
    "            json.dump(data, file, indent=2)\n",
    "        return True\n",
    "    except IOError as e:\n",
    "        print(f\"File write failed: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"\\nâœ“ Validate data before saving\")\n",
    "\n",
    "# Best Practice 3: Use appropriate formatting\n",
    "# For production: compact (no indent)\n",
    "production_json = json.dumps(data, separators=(',', ':'))\n",
    "print(f\"\\nâœ“ Production size: {len(production_json)} bytes\")\n",
    "\n",
    "# For development: readable (with indent)\n",
    "dev_json = json.dumps(data, indent=2)\n",
    "print(f\"âœ“ Development size: {len(dev_json)} bytes (more readable)\")\n",
    "\n",
    "# Best Practice 4: Handle encoding properly\n",
    "unicode_data = {\"message\": \"Hello ä¸–ç•Œ\", \"emoji\": \"ðŸŽ‰\"}\n",
    "\n",
    "# ASCII-safe (escape non-ASCII)\n",
    "ascii_json = json.dumps(unicode_data, ensure_ascii=True)\n",
    "print(f\"\\nâœ“ ASCII-safe: {ascii_json}\")\n",
    "\n",
    "# UTF-8 (preserve Unicode)\n",
    "utf8_json = json.dumps(unicode_data, ensure_ascii=False)\n",
    "print(f\"âœ“ UTF-8: {utf8_json}\")\n",
    "\n",
    "# Best Practice 5: Use sort_keys for consistency\n",
    "data_unsorted = {\"z\": 1, \"a\": 2, \"m\": 3}\n",
    "sorted_json = json.dumps(data_unsorted, sort_keys=True)\n",
    "print(f\"\\nâœ“ Sorted keys for version control: {sorted_json}\")\n",
    "\n",
    "# Best Practice 6: Don't parse JSON multiple times\n",
    "# Bad: parsing same data multiple times\n",
    "# for i in range(100):\n",
    "#     data = json.loads(json_string)  # Wasteful\n",
    "\n",
    "# Good: parse once, reuse\n",
    "json_string = '{\"key\": \"value\"}'\n",
    "parsed_once = json.loads(json_string)\n",
    "# Use parsed_once multiple times\n",
    "print(\"\\nâœ“ Parse JSON once, reuse the object\")\n",
    "\n",
    "# Summary of best practices\n",
    "best_practices = {\n",
    "    \"file_operations\": \"Always use 'with' statement\",\n",
    "    \"error_handling\": \"Wrap in try-except blocks\",\n",
    "    \"formatting\": \"Use indent for development, compact for production\",\n",
    "    \"encoding\": \"Use ensure_ascii=False for international text\",\n",
    "    \"validation\": \"Validate data before serialization\",\n",
    "    \"performance\": \"Use dump/load directly with files\",\n",
    "    \"version_control\": \"Use sort_keys=True for consistent output\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"JSON Best Practices Summary:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in best_practices.items():\n",
    "    print(f\"â€¢ {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# Cleanup demo files\n",
    "import os\n",
    "for file in [\"perf_test1.json\", \"perf_test2.json\", \"data.json\"]:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "print(\"\\nâœ“ Cleaned up demo files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
